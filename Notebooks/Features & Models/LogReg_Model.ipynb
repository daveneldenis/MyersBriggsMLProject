{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Myers Brigss ML Project: Logistical Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>and intj moments    sportscenter not top ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>i m finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one           course  to which i say i k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp    i enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>you re fired  that s another silly misconcept...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0  INFJ    and intj moments    sportscenter not top ten...\n",
       "1  ENTP   i m finding the lack of me in these posts ver...\n",
       "2  INTP   good one           course  to which i say i k...\n",
       "3  INTJ   dear intp    i enjoyed our conversation the o...\n",
       "4  ENTJ   you re fired  that s another silly misconcept..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the cleaned df\n",
    "cleaned_df = pd.read_csv('../../Resources/data/cleaned_mbti.csv', index_col=0)\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split type column to 4 combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>E-I</th>\n",
       "      <th>N-S</th>\n",
       "      <th>T-F</th>\n",
       "      <th>J-P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>and intj moments    sportscenter not top ten...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>i m finding the lack of me in these posts ver...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one           course  to which i say i k...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp    i enjoyed our conversation the o...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>you re fired  that s another silly misconcept...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text E-I N-S T-F J-P\n",
       "0  INFJ    and intj moments    sportscenter not top ten...   I   N   F   J\n",
       "1  ENTP   i m finding the lack of me in these posts ver...   E   N   T   P\n",
       "2  INTP   good one           course  to which i say i k...   I   N   T   P\n",
       "3  INTJ   dear intp    i enjoyed our conversation the o...   I   N   T   J\n",
       "4  ENTJ   you re fired  that s another silly misconcept...   E   N   T   J"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split type columns into four binary columns\n",
    "split_df = cleaned_df[['type','text']].copy()\n",
    "split_df['E-I'] = split_df['type'].str.extract('(.)[N,S]',1)\n",
    "split_df['N-S'] = split_df['type'].str.extract('[E,I](.)[F,T]',1)\n",
    "split_df['T-F'] = split_df['type'].str.extract('[N,S](.)[J,P]',1)\n",
    "split_df['J-P'] = split_df['type'].str.extract('[F,T](.)',1)\n",
    "split_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>E0-I1</th>\n",
       "      <th>N0-S1</th>\n",
       "      <th>F0-T1</th>\n",
       "      <th>J0-P1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>and intj moments    sportscenter not top ten...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>i m finding the lack of me in these posts ver...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one           course  to which i say i k...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp    i enjoyed our conversation the o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>you re fired  that s another silly misconcept...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  E0-I1  N0-S1  \\\n",
       "0  INFJ    and intj moments    sportscenter not top ten...      1      0   \n",
       "1  ENTP   i m finding the lack of me in these posts ver...      0      0   \n",
       "2  INTP   good one           course  to which i say i k...      1      0   \n",
       "3  INTJ   dear intp    i enjoyed our conversation the o...      1      0   \n",
       "4  ENTJ   you re fired  that s another silly misconcept...      0      0   \n",
       "\n",
       "   F0-T1  J0-P1  \n",
       "0      0      0  \n",
       "1      1      1  \n",
       "2      1      1  \n",
       "3      1      0  \n",
       "4      1      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode letters to numeric values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "encoded_df = cleaned_df[['type','text']].copy()\n",
    "encoded_df['E0-I1'] = le.fit_transform(split_df['E-I'])\n",
    "encoded_df['N0-S1'] = le.fit_transform(split_df['N-S'])\n",
    "encoded_df['F0-T1'] = le.fit_transform(split_df['T-F'])\n",
    "encoded_df['J0-P1'] = le.fit_transform(split_df['J-P'])\n",
    "\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'text', 'E0-I1', 'N0-S1', 'F0-T1', 'J0-P1'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = encoded_df[\"text\"].values\n",
    "y_all = encoded_df.drop(columns=['type', 'text'])\n",
    "\n",
    "# Split training and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_all_train, y_all_test = train_test_split(X, y_all, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjin9\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, defaultdict\n"
     ]
    }
   ],
   "source": [
    "# Define TFIDF verctorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=17000,\n",
    "    min_df=7,\n",
    "    max_df=0.8,\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1,3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vectors for X\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create log reg model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. No resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E-I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit E-I combination\n",
    "y_EI_train = y_all_train['E0-I1']\n",
    "y_EI_test = y_all_test['E0-I1']\n",
    "\n",
    "classifier.fit(X_train, y_EI_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Prediction  Actual\n",
       "2802           0       1\n",
       "2166           1       1\n",
       "1919           1       1\n",
       "360            0       0\n",
       "1115           1       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict outcomes for test data set\n",
    "y_EI_pred = classifier.predict(X_test)\n",
    "EI_result = pd.DataFrame({\"Prediction\": y_EI_pred, \"Actual\": y_EI_test})\n",
    "EI_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit N-S combination\n",
    "y_NS_train = y_all_train['N0-S1']\n",
    "y_NS_test = y_all_test['N0-S1']\n",
    "\n",
    "classifier.fit(X_train, y_NS_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Prediction  Actual\n",
       "2802           0       0\n",
       "2166           0       0\n",
       "1919           0       0\n",
       "360            0       0\n",
       "1115           0       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict outcomes for test data set\n",
    "y_NS_pred = classifier.predict(X_test)\n",
    "NS_result = pd.DataFrame({\"Prediction\": y_NS_pred, \"Actual\": y_NS_test})\n",
    "NS_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit F-T combination\n",
    "y_FT_train = y_all_train['F0-T1']\n",
    "y_FT_test = y_all_test['F0-T1']\n",
    "\n",
    "classifier.fit(X_train, y_FT_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Prediction  Actual\n",
       "2802           1       1\n",
       "2166           0       1\n",
       "1919           1       1\n",
       "360            0       0\n",
       "1115           1       1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict outcomes for test data set\n",
    "y_FT_pred = classifier.predict(X_test)\n",
    "FT_result = pd.DataFrame({\"Prediction\": y_FT_pred, \"Actual\": y_FT_test})\n",
    "FT_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### J-P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit F-T combination\n",
    "y_JP_train = y_all_train['J0-P1']\n",
    "y_JP_test = y_all_test['J0-P1']\n",
    "\n",
    "classifier.fit(X_train, y_JP_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Prediction  Actual\n",
       "2802           1       1\n",
       "2166           0       0\n",
       "1919           1       1\n",
       "360            0       1\n",
       "1115           0       0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict outcomes for test data set\n",
    "y_JP_pred = classifier.predict(X_test)\n",
    "JP_result = pd.DataFrame({\"Prediction\": y_JP_pred, \"Actual\": y_JP_test})\n",
    "JP_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic regression model accuracy for E-I: 0.846\n",
      " Logistic regression model accuracy for N-S: 0.871\n",
      " Logistic regression model accuracy for F-T: 0.848\n",
      " Logistic regression model accuracy for J-P: 0.799\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy score for each group\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f\" Logistic regression model accuracy for E-I: {accuracy_score(y_EI_test, y_EI_pred):.3f}\")\n",
    "print(f\" Logistic regression model accuracy for N-S: {accuracy_score(y_NS_test, y_NS_pred):.3f}\")\n",
    "print(f\" Logistic regression model accuracy for F-T: {accuracy_score(y_FT_test, y_FT_pred):.3f}\")\n",
    "print(f\" Logistic regression model accuracy for J-P: {accuracy_score(y_JP_test, y_JP_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for E0-I1 group:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.37      0.51       473\n",
      "          1       0.85      0.98      0.91      1696\n",
      "\n",
      "avg / total       0.84      0.85      0.82      2169\n",
      "\n",
      "Accuracy score: 0.846\n",
      "--------------------------\n",
      "Classification report for N0-S1 group:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93      1862\n",
      "          1       0.80      0.12      0.21       307\n",
      "\n",
      "avg / total       0.86      0.87      0.83      2169\n",
      "\n",
      "Accuracy score: 0.871\n",
      "--------------------------\n",
      "Classification report for F0-T1 group:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.86      0.86      1179\n",
      "          1       0.83      0.83      0.83       990\n",
      "\n",
      "avg / total       0.85      0.85      0.85      2169\n",
      "\n",
      "Accuracy score: 0.848\n",
      "--------------------------\n",
      "Classification report for J0-P1 group:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.61      0.70       842\n",
      "          1       0.79      0.92      0.85      1327\n",
      "\n",
      "avg / total       0.80      0.80      0.79      2169\n",
      "\n",
      "Accuracy score: 0.802\n"
     ]
    }
   ],
   "source": [
    "# check out classigication report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "report_EI = classification_report(y_EI_test, y_EI_pred)\n",
    "print(f\"Classification report for E0-I1 group:\")\n",
    "print(report_EI)\n",
    "print(f\"Accuracy score: {accuracy_score(y_EI_test, y_EI_pred):.3f}\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "report_NS = classification_report(y_NS_test, y_NS_pred)\n",
    "print(f\"Classification report for N0-S1 group:\")\n",
    "print(report_NS)\n",
    "print(f\"Accuracy score: {accuracy_score(y_NS_test, y_NS_pred):.3f}\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "report_FT = classification_report(y_FT_test, y_FT_pred)\n",
    "print(f\"Classification report for F0-T1 group:\")\n",
    "print(report_FT)\n",
    "print(f\"Accuracy score: {accuracy_score(y_FT_test, y_FT_pred):.3f}\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "report_JP = classification_report(y_JP_test, y_JP_pred)\n",
    "print(f\"Classification report for J0-P1 group:\")\n",
    "print(report_JP)\n",
    "print(f\"Accuracy score: {accuracy_score(y_JP_test, y_JP_pred_ros):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E-I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4980, 1: 4980})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement random oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "\n",
    "y_EI_train = y_all_train['E0-I1']\n",
    "y_EI_test = y_all_test['E0-I1']\n",
    "\n",
    "X_resampled_ros, y_EI_resampled_ros = ros.fit_sample(X_train, y_EI_train)\n",
    "\n",
    "from collections import Counter\n",
    "Counter(y_EI_resampled_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit E-I combination with oversampled x_train and y_EI_train\n",
    "\n",
    "classifier.fit(X_resampled_ros, y_EI_resampled_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict outcomes for test data set\n",
    "y_EI_pred_ros = classifier.predict(X_test)\n",
    "EI_result = pd.DataFrame({\"Prediction\": y_EI_pred_ros, \"Actual\": y_EI_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model weights\n",
    "pickle.dump(classifier, open('../../Resources/model_weights/model_EI.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 5616, 1: 5616})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resample N-S combination\n",
    "y_NS_train = y_all_train['N0-S1']\n",
    "y_NS_test = y_all_test['N0-S1']\n",
    "\n",
    "X_resampled_ros, y_NS_resampled_ros = ros.fit_sample(X_train, y_NS_train)\n",
    "\n",
    "Counter(y_NS_resampled_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit N-S combination with oversampled x_train and y_NS_train\n",
    "\n",
    "classifier.fit(X_resampled_ros, y_NS_resampled_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Prediction  Actual\n",
       "2802           0       0\n",
       "2166           0       0\n",
       "1919           0       0\n",
       "360            0       0\n",
       "1115           0       0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict outcomes for test data set\n",
    "y_NS_pred_ros = classifier.predict(X_test)\n",
    "NS_result = pd.DataFrame({\"Prediction\": y_NS_pred_ros, \"Actual\": y_NS_test})\n",
    "NS_result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model weights\n",
    "pickle.dump(classifier, open('../../Resources/model_weights/model_NS.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3515, 1: 3515})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resample F-T combination\n",
    "y_FT_train = y_all_train['F0-T1']\n",
    "y_FT_test = y_all_test['F0-T1']\n",
    "\n",
    "X_resampled_ros, y_FT_resampled_ros = ros.fit_sample(X_train, y_FT_train)\n",
    "\n",
    "Counter(y_FT_resampled_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit F-T combination with oversampled x_train and y_FT_train\n",
    "\n",
    "classifier.fit(X_resampled_ros, y_FT_resampled_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Prediction  Actual\n",
       "2802           1       1\n",
       "2166           0       1\n",
       "1919           1       1\n",
       "360            0       0\n",
       "1115           1       1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict outcomes for test data set\n",
    "y_FT_pred_ros = classifier.predict(X_test)\n",
    "FT_result = pd.DataFrame({\"Prediction\": y_FT_pred_ros, \"Actual\": y_FT_test})\n",
    "FT_result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model weights\n",
    "pickle.dump(classifier, open('../../Resources/model_weights/model_FT.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### J-P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3914, 0: 3914})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resample J-P combination\n",
    "y_JP_train = y_all_train['J0-P1']\n",
    "y_JP_test = y_all_test['J0-P1']\n",
    "\n",
    "X_resampled_ros, y_JP_resampled_ros = ros.fit_sample(X_train, y_JP_train)\n",
    "\n",
    "Counter(y_JP_resampled_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit J-P combination with oversampled x_train and y_JP_train\n",
    "\n",
    "classifier.fit(X_resampled_ros, y_JP_resampled_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Prediction  Actual\n",
       "2802           1       1\n",
       "2166           0       0\n",
       "1919           1       1\n",
       "360            0       1\n",
       "1115           0       0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict outcomes for test data set\n",
    "y_JP_pred_ros = classifier.predict(X_test)\n",
    "JP_result = pd.DataFrame({\"Prediction\": y_JP_pred_ros, \"Actual\": y_JP_test})\n",
    "JP_result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model weights\n",
    "pickle.dump(classifier, open('../../Resources/model_weights/model_JP.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic regression model accuracy for E-I: 0.857\n",
      " Logistic regression model accuracy for N-S: 0.903\n",
      " Logistic regression model accuracy for F-T: 0.846\n",
      " Logistic regression model accuracy for J-P: 0.802\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy score for each group\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f\" Logistic regression model accuracy for E-I: {accuracy_score(y_EI_test, y_EI_pred_ros):.3f}\")\n",
    "print(f\" Logistic regression model accuracy for N-S: {accuracy_score(y_NS_test, y_NS_pred_ros):.3f}\")\n",
    "print(f\" Logistic regression model accuracy for F-T: {accuracy_score(y_FT_test, y_FT_pred_ros):.3f}\")\n",
    "print(f\" Logistic regression model accuracy for J-P: {accuracy_score(y_JP_test, y_JP_pred_ros):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for E0-I1 group:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.68      0.68       473\n",
      "          1       0.91      0.91      0.91      1696\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2169\n",
      "\n",
      "Accuracy score: 0.857\n",
      "--------------------------\n",
      "Classification report for N0-S1 group:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.94      0.94      1862\n",
      "          1       0.65      0.68      0.66       307\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2169\n",
      "\n",
      "Accuracy score: 0.903\n",
      "--------------------------\n",
      "Classification report for F0-T1 group:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.84      0.86      1179\n",
      "          1       0.81      0.86      0.84       990\n",
      "\n",
      "avg / total       0.85      0.85      0.85      2169\n",
      "\n",
      "Accuracy score: 0.846\n",
      "--------------------------\n",
      "Classification report for J0-P1 group:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.74      0.74       842\n",
      "          1       0.84      0.84      0.84      1327\n",
      "\n",
      "avg / total       0.80      0.80      0.80      2169\n",
      "\n",
      "Accuracy score: 0.802\n"
     ]
    }
   ],
   "source": [
    "report_EI = classification_report(y_EI_test, y_EI_pred_ros)\n",
    "print(f\"Classification report for E0-I1 group:\")\n",
    "print(report_EI)\n",
    "print(f\"Accuracy score: {accuracy_score(y_EI_test, y_EI_pred_ros):.3f}\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "report_NS = classification_report(y_NS_test, y_NS_pred_ros)\n",
    "print(f\"Classification report for N0-S1 group:\")\n",
    "print(report_NS)\n",
    "print(f\"Accuracy score: {accuracy_score(y_NS_test, y_NS_pred_ros):.3f}\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "report_FT = classification_report(y_FT_test, y_FT_pred_ros)\n",
    "print(f\"Classification report for F0-T1 group:\")\n",
    "print(report_FT)\n",
    "print(f\"Accuracy score: {accuracy_score(y_FT_test, y_FT_pred_ros):.3f}\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "report_JP = classification_report(y_JP_test, y_JP_pred_ros)\n",
    "print(f\"Classification report for J0-P1 group:\")\n",
    "print(report_JP)\n",
    "print(f\"Accuracy score: {accuracy_score(y_JP_test, y_JP_pred_ros):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
